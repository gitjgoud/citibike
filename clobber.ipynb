{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trips and Stations\n",
    "* Create yearly trip parquet files\n",
    "* Create bike dock stations parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "import logging\n",
    "import requests, json\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "# CSV_DIR = DATA_DIR + \"tripdata_csv/\"\n",
    "PARQUET_DIR = DATA_DIR + \"tripdata_parquet/\"\n",
    "NY_DIR = PARQUET_DIR + \"NY/\"\n",
    "NJ_DIR = PARQUET_DIR + \"NJ/\"\n",
    "STATIONS_DIR = DATA_DIR + \"stations/\"\n",
    "PARQUET_EXTENSION = \".parquet\"\n",
    "STATION_INFO_URL = \"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\"\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "logging.info(\n",
    "    f\"{len(os.listdir(NJ_DIR))} Jersey City files and {len(os.listdir(NY_DIR))} New York City files\"\n",
    ")\n",
    "\n",
    "# schema for parquet files in\n",
    "TRIPDATA_COLUMN_DTYPES = {\n",
    "    \"tripduration\": \"int32\",\n",
    "    \"starttime\": \"datetime64\",\n",
    "    \"stoptime\": \"datetime64\",\n",
    "    \"startstationid\": \"category\",\n",
    "    \"startstationname\": \"category\",\n",
    "    \"startstationlatitude\": \"category\",\n",
    "    \"startstationlongitude\": \"category\",\n",
    "    \"endstationid\": \"category\",\n",
    "    \"endstationname\": \"category\",\n",
    "    \"endstationlatitude\": \"category\",\n",
    "    \"endstationlongitude\": \"category\",\n",
    "    \"bikeid\": \"category\",\n",
    "    \"usertype\": \"category\",\n",
    "    \"birthyear\": \"category\",\n",
    "    \"gender\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_monthly_trips(year, directory: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a merged parquet file from parquet files in a directory\n",
    "    :param year: the year (int) to merge monthly data for. if None, then merge all files in directory\n",
    "    :param directory: a directory containing parquet files with identical schema (column names) across files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if year:\n",
    "        range_start = str(year) + \"-01\"\n",
    "        range_end = str(year) + \"-13\"\n",
    "        month_files = sorted(\n",
    "            [\n",
    "                directory + f\n",
    "                for f in os.listdir(directory)\n",
    "                if range_start <= f <= range_end\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        month_files = sorted(\n",
    "            [\n",
    "                directory + f\n",
    "                for f in os.listdir(directory)\n",
    "                if f.endswith(PARQUET_EXTENSION)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    parquet_ddfs: list[dd.DataFrame] = []\n",
    "    for month_file in month_files:\n",
    "        if os.path.exists(month_file):\n",
    "            ddf = dd.read_parquet(month_file)\n",
    "            ddf.astype(TRIPDATA_COLUMN_DTYPES)\n",
    "            ddf[\"birthyear\"] = ddf[\"birthyear\"].astype(\n",
    "                \"str\"\n",
    "            )  # some issue with birthyear in particular\n",
    "            parquet_ddfs.append(ddf)\n",
    "\n",
    "    all_trips = dd.concat(parquet_ddfs)\n",
    "    filename = str(year) if year else \"alltrips\"\n",
    "    all_trips.to_parquet(\n",
    "        directory + filename + PARQUET_EXTENSION,\n",
    "        schema={\"birthyear\": pa.string()},\n",
    "        engine=\"pyarrow\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/tripdata_parquet/NY/2013-06.parquet', 'data/tripdata_parquet/NY/2013-07.parquet', 'data/tripdata_parquet/NY/2013-08.parquet', 'data/tripdata_parquet/NY/2013-09.parquet', 'data/tripdata_parquet/NY/2013-10.parquet', 'data/tripdata_parquet/NY/2013-11.parquet', 'data/tripdata_parquet/NY/2013-12.parquet', 'data/tripdata_parquet/NY/2014-01.parquet', 'data/tripdata_parquet/NY/2014-02.parquet', 'data/tripdata_parquet/NY/2014-03.parquet', 'data/tripdata_parquet/NY/2014-04.parquet', 'data/tripdata_parquet/NY/2014-05.parquet', 'data/tripdata_parquet/NY/2014-06.parquet', 'data/tripdata_parquet/NY/2014-07.parquet', 'data/tripdata_parquet/NY/2014-08.parquet', 'data/tripdata_parquet/NY/2014-09.parquet', 'data/tripdata_parquet/NY/2014-10.parquet', 'data/tripdata_parquet/NY/2014-11.parquet', 'data/tripdata_parquet/NY/2014-12.parquet', 'data/tripdata_parquet/NY/2015-01.parquet', 'data/tripdata_parquet/NY/2015-02.parquet', 'data/tripdata_parquet/NY/2015-03.parquet', 'data/tripdata_parquet/NY/2015-04.parquet', 'data/tripdata_parquet/NY/2015-05.parquet', 'data/tripdata_parquet/NY/2015-06.parquet', 'data/tripdata_parquet/NY/2015-07.parquet', 'data/tripdata_parquet/NY/2015-08.parquet', 'data/tripdata_parquet/NY/2015-09.parquet', 'data/tripdata_parquet/NY/2015-10.parquet', 'data/tripdata_parquet/NY/2015-11.parquet', 'data/tripdata_parquet/NY/2015-12.parquet', 'data/tripdata_parquet/NY/2016-01.parquet', 'data/tripdata_parquet/NY/2016-02.parquet', 'data/tripdata_parquet/NY/2016-03.parquet', 'data/tripdata_parquet/NY/2016-04.parquet', 'data/tripdata_parquet/NY/2016-05.parquet', 'data/tripdata_parquet/NY/2016-06.parquet', 'data/tripdata_parquet/NY/2016-07.parquet', 'data/tripdata_parquet/NY/2016-08.parquet', 'data/tripdata_parquet/NY/2016-09.parquet', 'data/tripdata_parquet/NY/2016-10.parquet', 'data/tripdata_parquet/NY/2016-11.parquet', 'data/tripdata_parquet/NY/2016-12.parquet', 'data/tripdata_parquet/NY/2017-01.parquet', 'data/tripdata_parquet/NY/2017-02.parquet', 'data/tripdata_parquet/NY/2017-03.parquet', 'data/tripdata_parquet/NY/2017-04.parquet', 'data/tripdata_parquet/NY/2017-05.parquet', 'data/tripdata_parquet/NY/2017-06.parquet', 'data/tripdata_parquet/NY/2017-07.parquet', 'data/tripdata_parquet/NY/2017-08.parquet', 'data/tripdata_parquet/NY/2017-09.parquet', 'data/tripdata_parquet/NY/2017-10.parquet', 'data/tripdata_parquet/NY/2017-11.parquet', 'data/tripdata_parquet/NY/2017-12.parquet', 'data/tripdata_parquet/NY/2018-01.parquet', 'data/tripdata_parquet/NY/2018-02.parquet', 'data/tripdata_parquet/NY/2018-03.parquet', 'data/tripdata_parquet/NY/2018-04.parquet', 'data/tripdata_parquet/NY/2018-05.parquet', 'data/tripdata_parquet/NY/2018-06.parquet', 'data/tripdata_parquet/NY/2018-07.parquet', 'data/tripdata_parquet/NY/2018-08.parquet', 'data/tripdata_parquet/NY/2018-09.parquet', 'data/tripdata_parquet/NY/2018-10.parquet', 'data/tripdata_parquet/NY/2018-11.parquet', 'data/tripdata_parquet/NY/2018-12.parquet', 'data/tripdata_parquet/NY/2019-01.parquet', 'data/tripdata_parquet/NY/2019-02.parquet', 'data/tripdata_parquet/NY/2019-03.parquet', 'data/tripdata_parquet/NY/2019-04.parquet', 'data/tripdata_parquet/NY/2019-05.parquet', 'data/tripdata_parquet/NY/2019-06.parquet', 'data/tripdata_parquet/NY/2019-07.parquet', 'data/tripdata_parquet/NY/2019-08.parquet', 'data/tripdata_parquet/NY/2019-09.parquet', 'data/tripdata_parquet/NY/2019-10.parquet', 'data/tripdata_parquet/NY/2019-11.parquet', 'data/tripdata_parquet/NY/2019-12.parquet', 'data/tripdata_parquet/NY/2020-01.parquet', 'data/tripdata_parquet/NY/2020-02.parquet', 'data/tripdata_parquet/NY/2020-03.parquet', 'data/tripdata_parquet/NY/2020-04.parquet', 'data/tripdata_parquet/NY/2020-05.parquet', 'data/tripdata_parquet/NY/2020-06.parquet', 'data/tripdata_parquet/NY/2020-07.parquet', 'data/tripdata_parquet/NY/2020-08.parquet', 'data/tripdata_parquet/NY/2020-09.parquet', 'data/tripdata_parquet/NY/2020-10.parquet', 'data/tripdata_parquet/NY/2020-11.parquet', 'data/tripdata_parquet/NY/2020-12.parquet', 'data/tripdata_parquet/NY/2021-01.parquet']\n",
      "CPU times: user 3min 45s, sys: 1min 23s, total: 5min 8s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create parquet file from all trip data (NY)\n",
    "# NOTE run this before running the below cell if you want this large file. running it after will not work\n",
    "merge_monthly_trips(year=None, directory=NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 1min 16s, total: 4min 46s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create yearly trip data parquet files\n",
    "for year in range(2013, 2022):\n",
    "    merge_monthly_trips(year, NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>startstationid</th>\n",
       "      <th>endstationid</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320</td>\n",
       "      <td>2019-01-01 00:01:47.4010</td>\n",
       "      <td>2019-01-01 00:07:07.5810</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>15839</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>2019-01-01 00:04:43.7360</td>\n",
       "      <td>2019-01-01 00:10:00.6080</td>\n",
       "      <td>519.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>32723</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591</td>\n",
       "      <td>2019-01-01 00:06:03.9970</td>\n",
       "      <td>2019-01-01 00:15:55.4380</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>3154.0</td>\n",
       "      <td>27451</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2719</td>\n",
       "      <td>2019-01-01 00:07:03.5450</td>\n",
       "      <td>2019-01-01 00:52:22.6500</td>\n",
       "      <td>504.0</td>\n",
       "      <td>3709.0</td>\n",
       "      <td>21579</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>2019-01-01 00:07:35.9450</td>\n",
       "      <td>2019-01-01 00:12:39.5020</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>35379</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551512</th>\n",
       "      <td>729</td>\n",
       "      <td>2019-10-31 23:59:12.1900</td>\n",
       "      <td>2019-11-01 00:11:21.4860</td>\n",
       "      <td>237.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>25725</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551513</th>\n",
       "      <td>645</td>\n",
       "      <td>2019-10-31 23:59:17.0470</td>\n",
       "      <td>2019-11-01 00:10:02.9450</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>39583</td>\n",
       "      <td>Customer</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551514</th>\n",
       "      <td>257</td>\n",
       "      <td>2019-10-31 23:59:22.5140</td>\n",
       "      <td>2019-11-01 00:03:40.2600</td>\n",
       "      <td>3798.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>21240</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551515</th>\n",
       "      <td>466</td>\n",
       "      <td>2019-10-31 23:59:23.1710</td>\n",
       "      <td>2019-11-01 00:07:09.2050</td>\n",
       "      <td>328.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>34916</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551516</th>\n",
       "      <td>81</td>\n",
       "      <td>2019-10-31 23:59:51.5170</td>\n",
       "      <td>2019-11-01 00:01:13.2150</td>\n",
       "      <td>539.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>25745</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20551517 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tripduration                 starttime                  stoptime  \\\n",
       "0                  320  2019-01-01 00:01:47.4010  2019-01-01 00:07:07.5810   \n",
       "1                  316  2019-01-01 00:04:43.7360  2019-01-01 00:10:00.6080   \n",
       "2                  591  2019-01-01 00:06:03.9970  2019-01-01 00:15:55.4380   \n",
       "3                 2719  2019-01-01 00:07:03.5450  2019-01-01 00:52:22.6500   \n",
       "4                  303  2019-01-01 00:07:35.9450  2019-01-01 00:12:39.5020   \n",
       "...                ...                       ...                       ...   \n",
       "20551512           729  2019-10-31 23:59:12.1900  2019-11-01 00:11:21.4860   \n",
       "20551513           645  2019-10-31 23:59:17.0470  2019-11-01 00:10:02.9450   \n",
       "20551514           257  2019-10-31 23:59:22.5140  2019-11-01 00:03:40.2600   \n",
       "20551515           466  2019-10-31 23:59:23.1710  2019-11-01 00:07:09.2050   \n",
       "20551516            81  2019-10-31 23:59:51.5170  2019-11-01 00:01:13.2150   \n",
       "\n",
       "          startstationid  endstationid  bikeid    usertype birthyear  gender  \n",
       "0                 3160.0        3283.0   15839  Subscriber      1971       1  \n",
       "1                  519.0         518.0   32723  Subscriber      1964       1  \n",
       "2                 3171.0        3154.0   27451  Subscriber      1987       1  \n",
       "3                  504.0        3709.0   21579  Subscriber      1990       1  \n",
       "4                  229.0         503.0   35379  Subscriber      1979       1  \n",
       "...                  ...           ...     ...         ...       ...     ...  \n",
       "20551512           237.0         311.0   25725  Subscriber      1995       1  \n",
       "20551513          3259.0         461.0   39583    Customer      1969       0  \n",
       "20551514          3798.0         505.0   21240  Subscriber      1985       1  \n",
       "20551515           328.0         361.0   34916  Subscriber      1989       0  \n",
       "20551516           539.0        3093.0   25745  Subscriber      1990       1  \n",
       "\n",
       "[20551517 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: read a yearly parquet file (2019)\n",
    "\n",
    "trip_columns = [\n",
    "    \"tripduration\",\n",
    "    \"starttime\",\n",
    "    \"stoptime\",\n",
    "    \"startstationid\",\n",
    "    \"endstationid\",\n",
    "    \"bikeid\",\n",
    "    \"usertype\",\n",
    "    \"birthyear\",\n",
    "    \"gender\",\n",
    "]  # specify columns you want to read\n",
    "test = pd.read_parquet(\n",
    "    NY_DIR + \"2019.parquet\", engine=\"pyarrow\", columns=trip_columns\n",
    ").reset_index()\n",
    "test.drop(test.columns[0], axis=1, inplace=True)  # drop the dask index\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(STATIONS_DIR):\n",
    "    os.makedirs(os.path.dirname(STATIONS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_stations(year, directory):\n",
    "    \"\"\"\n",
    "    Creates station table for year, saves to parquet file\n",
    "    :param year: year to create stations for using trip data for that year\n",
    "    :param directory: directory with the trip data parquet file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    trip_filepath = directory + str(year) + PARQUET_EXTENSION\n",
    "    trips = pd.read_parquet(trip_filepath, engine=\"pyarrow\").reset_index()\n",
    "    trips.drop(trips.columns[0], axis=1, inplace=True)  # drop the dask index\n",
    "\n",
    "    station_columns = [\n",
    "        \"startstationid\",\n",
    "        \"startstationname\",\n",
    "        \"startstationlatitude\",\n",
    "        \"startstationlongitude\",\n",
    "    ]\n",
    "    stations = trips[station_columns]\n",
    "    col_rename = {\n",
    "        \"startstationid\": \"stationid\",\n",
    "        \"startstationname\": \"stationname\",\n",
    "        \"startstationlatitude\": \"latitude\",\n",
    "        \"startstationlongitude\": \"longitude\",\n",
    "    }\n",
    "    stations.rename(columns=col_rename, inplace=True)\n",
    "    stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
    "\n",
    "    stations_filepath = STATIONS_DIR + str(year) + PARQUET_EXTENSION\n",
    "    stations.to_parquet(stations_filepath, engine=\"pyarrow\")\n",
    "\n",
    "    # when reading a trip parquet file, just specify the columns to use\n",
    "    # # remove unneeded cols from trips and save back to itself\n",
    "    # drop_cols = [\n",
    "    #     \"startstationname\",\n",
    "    #     \"startstationlatitude\",\n",
    "    #     \"startstationlongitude\",\n",
    "    #     \"endstationname\",\n",
    "    #     \"endstationlatitude\",\n",
    "    #     \"endstationlongitude\",\n",
    "    # ]\n",
    "    # trips.drop(drop_cols, axis=1, inplace=True)\n",
    "    # trips.to_parquet(directory + str(year) + PARQUET_EXTENSION, schema={\"birthyear\": pa.string()}, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 3min 50s, total: 6min 35s\n",
      "Wall time: 6min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.rename(columns=col_rename, inplace=True)\n",
      "/var/folders/zx/f3rt3pyx58xg7vm_jv6_g3jh0000gn/T/ipykernel_88710/4114168547.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(2013, 2022):\n",
    "    create_stations(year, NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_stations() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return merged yearly station files\n",
    "    \"\"\"\n",
    "    stations_dfs = []\n",
    "    stations_files = [\n",
    "        f for f in os.listdir(STATIONS_DIR) if not f.startswith(\"stations\")\n",
    "    ]\n",
    "    for station_file in stations_files:\n",
    "        filepath = STATIONS_DIR + station_file\n",
    "        stations_dfs.append(pd.read_parquet(filepath))\n",
    "\n",
    "    all_stations = pd.concat(stations_dfs)\n",
    "    all_stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
    "\n",
    "    return all_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_station_capacity(stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds station capacity info from Citibike GBFS feed\n",
    "    :param stations:\n",
    "    :return: stations with capacity info\n",
    "    \"\"\"\n",
    "    # get station info\n",
    "    url = requests.get(STATION_INFO_URL)\n",
    "    data = json.loads(url.text)\n",
    "    station_details = pd.DataFrame.from_dict(data[\"data\"][\"stations\"])\n",
    "\n",
    "    # extract capacity and merge back to dataframe\n",
    "    station_details = station_details[[\"name\", \"capacity\"]]\n",
    "    station_details.rename(columns={\"name\": \"stationname\"}, inplace=True)\n",
    "\n",
    "    return stations.merge(station_details, how=\"left\", on=\"stationname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_station_geodata(stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds station geodata info\n",
    "    :param stations:\n",
    "    :return: station with geodata info\n",
    "    \"\"\"\n",
    "    logging.debug(\"reverse geocoding boro and neighbourhood, wait 15-20 mins...\")\n",
    "    geolocator = Nominatim(user_agent=\"bikegeocode\")\n",
    "    reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "    locations_lst = []\n",
    "    for index, row in stations.iterrows():\n",
    "        locations_lst.append(\n",
    "            reverse(\"{}, {}\".format(row[\"latitude\"], row[\"longitude\"])).raw[\"address\"]\n",
    "        )\n",
    "    logging.debug(\"geocode complete, merging...\")\n",
    "    locations = pd.DataFrame(locations_lst, index=stations.stationid).reset_index()\n",
    "    locations = locations[[\"stationid\", \"neighbourhood\", \"suburb\", \"postcode\"]]\n",
    "    locations.rename(columns={\"suburb\": \"boro\", \"postcode\": \"zipcode\"}, inplace=True)\n",
    "    locations = locations.astype(\"category\")\n",
    "\n",
    "    return stations.merge(locations, how=\"left\", on=\"stationid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# merge yearly stations data, get capacity, get geodata, save\n",
    "# TODO get elevation\n",
    "stations = merge_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stations = add_station_capacity(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /reverse?lat=40.75227093837409&lon=-73.98770570755005&format=json&addressdetails=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 713 ms, total: 5.37 s\n",
      "Wall time: 23min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stations = add_station_geodata(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stations.to_parquet(STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>stationname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>capacity</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>boro</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.0</td>\n",
       "      <td>1 Ave &amp; E 44 St</td>\n",
       "      <td>40.750020</td>\n",
       "      <td>-73.969053</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Turtle Bay</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10017-6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434.0</td>\n",
       "      <td>9 Ave &amp; W 18 St</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Chelsea District</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>491.0</td>\n",
       "      <td>E 24 St &amp; Park Ave S</td>\n",
       "      <td>40.740964</td>\n",
       "      <td>-73.986022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan Community Board 5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384.0</td>\n",
       "      <td>Fulton St &amp; Waverly Ave</td>\n",
       "      <td>40.683178</td>\n",
       "      <td>-73.965964</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>474.0</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Midtown South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>3685.0</td>\n",
       "      <td>Prospect Park - 5 Year Anniversary Celebration</td>\n",
       "      <td>40.660652</td>\n",
       "      <td>-73.964590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>3695.0</td>\n",
       "      <td>E 5 St &amp; 2 Ave</td>\n",
       "      <td>40.726870</td>\n",
       "      <td>-73.989190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>3700.0</td>\n",
       "      <td>E 87 St &amp; 3 Ave</td>\n",
       "      <td>40.779406</td>\n",
       "      <td>-73.953336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carnegie Hill</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>3805.0</td>\n",
       "      <td>E 80 St &amp; Park Ave</td>\n",
       "      <td>40.776173</td>\n",
       "      <td>-73.959757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan Community Board 8</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>3747.0</td>\n",
       "      <td>E 84 St &amp; 3 Ave</td>\n",
       "      <td>40.777554</td>\n",
       "      <td>-73.955128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stationid                                     stationname   latitude  \\\n",
       "0         455.0                                 1 Ave & E 44 St  40.750020   \n",
       "1         434.0                                 9 Ave & W 18 St  40.743174   \n",
       "2         491.0                            E 24 St & Park Ave S  40.740964   \n",
       "3         384.0                         Fulton St & Waverly Ave  40.683178   \n",
       "4         474.0                                 5 Ave & E 29 St  40.745168   \n",
       "...         ...                                             ...        ...   \n",
       "1425     3685.0  Prospect Park - 5 Year Anniversary Celebration  40.660652   \n",
       "1426     3695.0                                  E 5 St & 2 Ave  40.726870   \n",
       "1427     3700.0                                 E 87 St & 3 Ave  40.779406   \n",
       "1428     3805.0                              E 80 St & Park Ave  40.776173   \n",
       "1429     3747.0                                 E 84 St & 3 Ave  40.777554   \n",
       "\n",
       "      longitude  capacity                neighbourhood       boro     zipcode  \n",
       "0    -73.969053      59.0                   Turtle Bay  Manhattan  10017-6927  \n",
       "1    -74.003664      60.0             Chelsea District  Manhattan       10019  \n",
       "2    -73.986022       NaN  Manhattan Community Board 5  Manhattan       10010  \n",
       "3    -73.965964      31.0                          NaN   Brooklyn       11238  \n",
       "4    -73.986831      56.0                Midtown South  Manhattan       10035  \n",
       "...         ...       ...                          ...        ...         ...  \n",
       "1425 -73.964590       NaN                          NaN   Brooklyn       11225  \n",
       "1426 -73.989190       NaN                 East Village  Manhattan       10003  \n",
       "1427 -73.953336       NaN                Carnegie Hill  Manhattan       10028  \n",
       "1428 -73.959757       NaN  Manhattan Community Board 8  Manhattan       10075  \n",
       "1429 -73.955128       NaN                          NaN  Manhattan       10028  \n",
       "\n",
       "[1430 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO FIX two capacity columns\n",
    "# example: read stations (all stations seen across all years)\n",
    "stations = pd.read_parquet(\n",
    "    STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\"\n",
    ")\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
