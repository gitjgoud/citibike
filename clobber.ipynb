{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP!! Summarize all the Citibike trip data CSVs\n",
    "Trying out\n",
    "* Dask dataframes\n",
    "* SQL\n",
    "* creating summary df from monthly CSVs\n",
    "* ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "CSV_DIR = DATA_DIR + \"tripdata_csv/\"\n",
    "NY_DIR = CSV_DIR + \"NY/\"\n",
    "NJ_DIR = CSV_DIR + \"NJ/\"\n",
    "\n",
    "DB_FILE = \"data/tripdata.db\"\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "JC_DATA = os.listdir(NJ_DIR)  # NOTE: this includes Hoboken and Jersey City\n",
    "NYC_DATA = os.listdir(NY_DIR)\n",
    "\n",
    "logging.info(\n",
    "    f\"{len(JC_DATA)} Jersey City files and {len(NYC_DATA)} New York City files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data ranges for NYC and NJ\n",
    "# NOTE: data schema changes beginning 2021-02\n",
    "# See: https://citibikenyc.com/system-data\n",
    "SCHEMA_CHANGE_DATE = \"2021-02\"\n",
    "# nyc_start = (2013, 6)\n",
    "# nyc_change = (2021, 2)\n",
    "# nyc_end = (2022, 2)\n",
    "\n",
    "# nj_start = (2015, 9)\n",
    "# nj_change = nyc_change\n",
    "# nj_end = nyc_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CSV paths for NYC, JC (pre and post schema change)\n",
    "nyc_old = sorted([NY_DIR + f for f in os.listdir(NY_DIR) if f < SCHEMA_CHANGE_DATE])\n",
    "nyc_new = sorted([NY_DIR + f for f in os.listdir(NY_DIR) if f >= SCHEMA_CHANGE_DATE])\n",
    "\n",
    "jc_old = sorted([NJ_DIR + f for f in os.listdir(NJ_DIR) if f < SCHEMA_CHANGE_DATE])\n",
    "jc_new = sorted([NJ_DIR + f for f in os.listdir(NJ_DIR) if f >= SCHEMA_CHANGE_DATE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO only works for old schema at the moment\n",
    "def summarise_months(outfilename: str, months: list):\n",
    "    \"\"\"\n",
    "    Writes monthly summary given list of monthly trip data\n",
    "\n",
    "    :param outfilename: where to write the summary csv\n",
    "    :param months: list of CSVs for the monthly trip data\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "\n",
    "    for file in months:\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = [col.lower().replace(\" \", \"\") for col in df.columns]\n",
    "        # logging.debug(f'{file}: {list(df.columns)}')\n",
    "\n",
    "        year_month = file.split(\"/\")[-1].removesuffix(\".csv\")  # YYYYMM\n",
    "\n",
    "        summary = pd.Series(dtype=object)\n",
    "        summary[\"datetime\"] = year_month\n",
    "        summary[\"counttrips\"] = df.shape[0]\n",
    "        summary[\"meanduration\"] = df.tripduration.mean()\n",
    "        summary[\"modestartstationid\"] = df.startstationid.mode()\n",
    "        summary[\"modestartstationname\"] = df.startstationname.mode()\n",
    "        summary[\"modestartstationlatitude\"] = df.startstationlatitude.mode()\n",
    "        summary[\"modestartstationlongitude\"] = df.startstationlongitude.mode()\n",
    "        summary[\"modeendstationid\"] = df.endstationid.mode()\n",
    "        summary[\"modeendstationname\"] = df.endstationname.mode()\n",
    "        summary[\"modeendstationlatitude\"] = df.endstationlatitude.mode()\n",
    "        summary[\"modeendstationlongitude\"] = df.endstationlongitude.mode()\n",
    "\n",
    "        if \"usertype\" in df.columns:\n",
    "            summary[\"usertypevalues\"] = df.usertype.value_counts()\n",
    "        elif \"member_casual\" in df.columns:\n",
    "            summary[\"usertypevalues\"] = df.member_casual.value_counts()\n",
    "\n",
    "        if \"gender\" in df.columns:\n",
    "            summary[\"gendervalues\"] = df.gender.value_counts()\n",
    "\n",
    "        summaries.append(summary)\n",
    "\n",
    "    summary_df = pd.DataFrame()\n",
    "    summary_df = summary_df.append(\n",
    "        summaries\n",
    "    )  # TODO use concat instead to suppress warning\n",
    "    summary_df.set_index(\"datetime\")\n",
    "    summary_df.to_csv(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write summary data month by month for NYC and NJ\n",
    "summarise_months(DATA_DIR + \"summary_nyc_old_schema.csv\", nyc_old)\n",
    "summarise_months(DATA_DIR + \"summary_jc_old_schema.csv\", jc_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read summary\n",
    "nyc_old_schema_summary = pd.read_csv(\"data/summary_nyc_old_schema.csv\", index_col=0)\n",
    "nyc_old_schema_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clobber_year(year=2019, state=\"NY\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Writes a csv to `data/` with given `outfilename` that is all monthly trip data for that `year`\n",
    "\n",
    "    :param year: the year for which to concatenate data files\n",
    "    :param outfilename: the file to write to. E.g., 'clobber_2019.csv'\n",
    "    :param state: 'NY' or 'NJ'. default 'NY'\n",
    "    :return: the merged dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    range_start = str(year) + \"-01\"\n",
    "    range_end = str(year) + \"-13\"  # Not sure why I have to select 13 here...\n",
    "    files = None\n",
    "    if state == \"NY\":\n",
    "        files = sorted(\n",
    "            [NY_DIR + f for f in os.listdir(NY_DIR) if range_start <= f <= range_end]\n",
    "        )\n",
    "    elif state == \"NJ\":\n",
    "        files = sorted(\n",
    "            [NJ_DIR + f for f in os.listdir(NJ_DIR) if range_start <= f <= range_end]\n",
    "        )\n",
    "    else:\n",
    "        raise IndexError(f\"No data for state: {state}\")\n",
    "\n",
    "    logging.debug(f\"Will merge these files: {files}, number of files: {len(files)}\")\n",
    "\n",
    "    # Concatenate all monthly data in range\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = [col.lower().replace(\" \", \"\") for col in df.columns]\n",
    "        logging.debug(f\"Appending df file: {file}...\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    logging.debug(f\"Merging dataframes...\")\n",
    "    clobbered = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    return clobbered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get 2019 data for testing\n",
    "year_2019 = clobber_year(2019, \"NY\")\n",
    "year_2019.to_csv(\"data/NY_2019.csv\")\n",
    "year_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "year_2019.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read JC summary\n",
    "jc_old_schema_summary = pd.read_csv(\"data/summary_nyc_old_schema.csv\", index_col=0)\n",
    "jc_old_schema_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clobber all old nyc CSVs NOTE THIS CRASHES COMPUTER\n",
    "\n",
    "\n",
    "# nyc_old_dfs = []\n",
    "# for file in nyc_old:\n",
    "#     print(f'file {NY_DIR + file}')\n",
    "#     df = pd.read_csv(NY_DIR + file)\n",
    "#     nyc_old_dfs.append(df)\n",
    "#\n",
    "# nyc_old_df = pd.concat(nyc_old_dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# ddf = dd.read_csv(nyc_old,\n",
    "#                   dtype={'birth year': 'object',\n",
    "#                          'end station id': 'float64'})\n",
    "#\n",
    "# # columns are Sentence Cased for some CSVs and lower cased for others\n",
    "# ddf = ddf.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ddf.describe().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
