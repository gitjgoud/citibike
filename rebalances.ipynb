{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rebalances [2019]\n",
    "Citibike does not provide data regarding bike rebalances, however, a bike that starts from a station where it did not end its previous trip it likely was either rebalanced or taken out of service. We will assume the former.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import to_datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import gc\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Bike Teleports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_select = [\n",
    "    \"starttime\",\n",
    "    \"stoptime\",\n",
    "    \"startstationid\",\n",
    "    \"startstationname\",\n",
    "    \"startstationlatitude\",\n",
    "    \"startstationlongitude\",\n",
    "    \"endstationid\",\n",
    "    \"endstationname\",\n",
    "    \"endstationlatitude\",\n",
    "    \"endstationlongitude\",\n",
    "    \"bikeid\",\n",
    "]\n",
    "# declare category column type to reduce memory usage compared to object\n",
    "# consider changing float64 to float32, datetime64 to 32 if possible, ids to ints\n",
    "col_types = {\n",
    "    \"startstationid\": \"category\",\n",
    "    \"startstationname\": \"category\",\n",
    "    \"endstationid\": \"category\",\n",
    "    \"endstationname\": \"category\",\n",
    "    \"bikeid\": \"category\",\n",
    "}\n",
    "\n",
    "\n",
    "rides_raw = pd.read_csv(\n",
    "    \"data/NY_2019.csv\",\n",
    "    index_col=False,\n",
    "    parse_dates=[\"starttime\", \"stoptime\"],\n",
    "    usecols=col_select,\n",
    "    dtype=col_types,\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame.from_records(\n",
    "    [\n",
    "        (\n",
    "            col,\n",
    "            rides_raw[col].nunique(),\n",
    "            rides_raw[col].dtype,\n",
    "            rides_raw[col].memory_usage(deep=True),\n",
    "        )\n",
    "        for col in rides_raw.columns\n",
    "    ],\n",
    "    columns=[\"Column Name\", \"Unique\", \"Data Type\", \"Memory Usage\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison to when left as objects\n",
    "\n",
    "# Column  Name\t              Unique\t    Data Type\t      Memory Usage\n",
    "# 0\t      starttime\t          20539444\t  datetime64[ns]\t 164413704\n",
    "# 1\t      stoptime\t          20539225\t  datetime64[ns]\t 164413704\n",
    "# 2\t      startstationid      936\t      float64\t         164413704\n",
    "# 3\t      startstationname\t  938\t      object\t        1574199724\n",
    "# 4\t      endstationid\t      973\t      float64\t         164413704\n",
    "# 5\t      endstationname\t  976\t      object\t        1573922082\n",
    "# 6\t      bikeid\t          19571\t      int64\t             164413704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order trips sequentially by bike\n",
    "rides = rides_raw.sort_values(by=[\"bikeid\", \"starttime\"])\n",
    "\n",
    "# create an dummy dataframe ot offset when merging\n",
    "offset = pd.DataFrame(\n",
    "    {\n",
    "        \"starttime\": pd.to_datetime(\"2010-09-01\"),\n",
    "        \"startstationid\": 0,\n",
    "        \"stoptime\": pd.to_datetime(\"2010-09-01\"),\n",
    "        \"endstationid\": 0,\n",
    "        \"bikeid\": 0,\n",
    "    },\n",
    "    index=[0],\n",
    ")\n",
    "\n",
    "# offset rides1 (start stations) to track end station, rides 1 for start station\n",
    "rides1 = (\n",
    "    pd.concat([offset, rides])\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\"bikeid\": \"bikeid1\"})\n",
    ")\n",
    "rides2 = (\n",
    "    pd.concat([rides, offset])\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\"bikeid\": \"bikeid2\"})\n",
    ")\n",
    "\n",
    "# concat horizontally - a ride would start from the same endstation unless rebalanced\n",
    "rides = pd.concat(\n",
    "    [\n",
    "        rides1[[\"bikeid1\", \"stoptime\", \"endstationid\", \"endstationname\"]],\n",
    "        rides2[[\"bikeid2\", \"starttime\", \"startstationid\", \"startstationname\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# remove temp dataframes from memory\n",
    "del [[offset, rides1, rides2]]\n",
    "gc.collect()\n",
    "\n",
    "rides.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for rebalances - bikeid = same, different stop and start stations\n",
    "rebal = rides[\n",
    "    [\n",
    "        \"bikeid1\",\n",
    "        \"stoptime\",\n",
    "        \"endstationid\",\n",
    "        \"endstationname\",\n",
    "        \"starttime\",\n",
    "        \"startstationid\",\n",
    "        \"startstationname\",\n",
    "    ]\n",
    "].loc[(rides.bikeid1 == rides.bikeid2) & (rides.startstationid != rides.endstationid)]\n",
    "\n",
    "rebal.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rebal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rides.shape)\n",
    "print(rebal.shape)\n",
    "print(\"The ratio of rebalances to rides in 2019 is: \", rebal.shape[0] / rides.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top20 rebalances\n",
    "rebalout = (\n",
    "    rebal[\"endstationname\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"Station\", \"endstationname\": \"Count_Out\"})[:20]\n",
    ")\n",
    "rebalin = (\n",
    "    rebal[\"startstationname\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"Station\", \"startstationname\": \"Count_In\"})[:20]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Citi Bike Rebalancing [2019] From Stations\")\n",
    "sns.barplot(y=rebalout.Station, x=rebalout.Count_Out, orient=\"h\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Citi Bike Rebalancing [2019] To Stations\")\n",
    "sns.barplot(y=rebalin.Station, x=rebalin.Count_In, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoencode - https://towardsdatascience.com/reverse-geocoding-with-nyc-bike-share-data-cdef427987f8\n",
    "geolocator = Nominatim(user_agent=\"nsp023@gmail.com\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1, max_retries=0)\n",
    "\n",
    "stations = rides_raw[\n",
    "    [\n",
    "        \"startstationid\",\n",
    "        \"startstationname\",\n",
    "        \"startstationlatitude\",\n",
    "        \"startstationlongitude\",\n",
    "    ]\n",
    "].drop_duplicates(subset=[\"startstationid\"])\n",
    "stations.rename(\n",
    "    columns={\n",
    "        \"startstationid\": \"stationid\",\n",
    "        \"startstationname\": \"stationname\",\n",
    "        \"startstationlatitude\": \"latitude\",\n",
    "        \"startstationlongitude\": \"longitude\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "stations.set_index(\"stationid\", inplace=True)\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave commented out - use CSV created below\n",
    "\n",
    "# locations_lst=[]\n",
    "# for index, row in stations.iterrows():\n",
    "#     locations_lst.append(reverse(\"{}, {}\".format(row['latitude'],\\\n",
    "#     row['longitude'])).raw['address'])\n",
    "\n",
    "# pd.DataFrame(locations_lst[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.DataFrame(\n",
    "    index=stations.index,\n",
    "    data=locations_lst,\n",
    "    columns=[\"neighbourhood\", \"suburb\", \"postcode\"],\n",
    ")\n",
    "locations.rename(\n",
    "    columns={\"neighbourhood\": \"neighborhood\", \"suburb\": \"boro\", \"postcode\": \"zipcode\"},\n",
    "    inplace=True,\n",
    ")\n",
    "locations[\"neighborhood\"] = locations[\"neighborhood\"].astype(\"category\")\n",
    "locations[\"boro\"] = locations[\"boro\"].astype(\"category\")\n",
    "locations[[\"stationname\", \"latitude\", \"longitude\"]] = stations[\n",
    "    [\"stationname\", \"latitude\", \"longitude\"]\n",
    "]\n",
    "locations.reset_index(inplace=True)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.to_csv(\n",
    "    \"data/locations_NY_2019.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df166cf616f39a8b0c2f66e83ba2afdd6bfc8b57008690bcf278f179dbfb1b31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
