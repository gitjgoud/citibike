{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Boro and Neighborhood by station coordinates + EDA\n",
    "This exercise was done using the NYC_2019.csv dataset. Revisit data cleaning section if using something different.\n",
    "\n",
    "Skip import section for EDA\n",
    "\n",
    "TODO:\n",
    "- figure out where the bronx went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Station Data & Reverse Geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data of interest\n",
    "datapath = \"data/NY_2019.csv\"\n",
    "\n",
    "col_select = [\n",
    "    \"startstationid\",\n",
    "    \"startstationname\",\n",
    "    \"startstationlatitude\",\n",
    "    \"startstationlongitude\",\n",
    "]\n",
    "col_types = {\"startstationid\": \"category\", \"startstationname\": \"category\"}\n",
    "\n",
    "stations = pd.read_csv(datapath, index_col=False, usecols=col_select, dtype=col_types)\n",
    "\n",
    "# format, drop duplicates, drop na\n",
    "stations.rename(\n",
    "    columns={\n",
    "        \"startstationid\": \"stationid\",\n",
    "        \"startstationname\": \"stationname\",\n",
    "        \"startstationlatitude\": \"latitude\",\n",
    "        \"startstationlongitude\": \"longitude\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
    "stations.dropna(subset=[\"stationid\"], inplace=True)\n",
    "stations.set_index(\"stationid\", inplace=True)\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize geocode\n",
    "geolocator = Nominatim(user_agent=\"bikegeocode\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1, max_retries=0)\n",
    "\n",
    "# pull geolocation data for each station\n",
    "locations_lst = []\n",
    "for index, row in stations.iterrows():\n",
    "    locations_lst.append(\n",
    "        reverse(\"{}, {}\".format(row[\"latitude\"], row[\"longitude\"])).raw[\"address\"]\n",
    "    )\n",
    "\n",
    "pd.DataFrame(locations_lst[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select desired fields from geo data, then create a new dataframe using stationid as index\n",
    "\n",
    "locations = pd.DataFrame(\n",
    "    index=stations.index,\n",
    "    data=locations_lst,\n",
    "    columns=[\"neighbourhood\", \"suburb\", \"postcode\"],\n",
    ")\n",
    "locations.rename(\n",
    "    columns={\"neighbourhood\": \"neighborhood\", \"suburb\": \"boro\", \"postcode\": \"zipcode\"},\n",
    "    inplace=True,\n",
    ")\n",
    "locations[\"neighborhood\"] = locations[\"neighborhood\"].astype(\"category\")\n",
    "locations[\"boro\"] = locations[\"boro\"].astype(\"category\")\n",
    "locations[[\"stationname\", \"latitude\", \"longitude\"]] = stations[\n",
    "    [\"stationname\", \"latitude\", \"longitude\"]\n",
    "]\n",
    "locations.zipcode = locations.zipcode.str[:5]\n",
    "\n",
    "locations.reset_index(inplace=True)\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where did the bronx go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Locations Data\n",
    "\n",
    "!!!CAUTION!!!\n",
    "\n",
    "this was done with NYC_2019.csv data - if a new dataset is provided this must be revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[locations.stationid.isna()]\n",
    "# these should have been dropped when importing stations dataframe - this is just a confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[locations.zipcode.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually fill in missing zips from google maps (selecting location near street intersection)\n",
    "locations.loc[locations.stationid == \"524.0\", \"zipcode\"] = \"10036\"\n",
    "locations.loc[locations.stationid == \"3263.0\", \"zipcode\"] = \"10003\"\n",
    "locations.loc[locations.stationid == \"3443.0\", \"zipcode\"] = \"10019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[locations.zipcode.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for imputing neighborhood with mode value of a given zip\n",
    "neighborhood_dict = (\n",
    "    locations.groupby(\"zipcode\")[\"neighborhood\"].agg(pd.Series.mode).to_dict()\n",
    ")\n",
    "neighborhood_dict\n",
    "\n",
    "# There still appears to be a lot of uncertainty in which neighborhood is associated with a given zip\n",
    "# some zips have several mode values, while some have none.\n",
    "# no further work with neighborhoods at this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for imputing boro with mode value of a given zip\n",
    "boro_dict = locations.groupby(\"zipcode\")[\"boro\"].agg(pd.Series.mode).to_dict()\n",
    "boro_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually fill the few with missing values\n",
    "boro_dict[\"11209\"] = \"Brooklyn\"\n",
    "boro_dict[\"11227\"] = \"Brooklyn\"\n",
    "boro_dict[\"11232\"] = \"Brooklyn\"\n",
    "boro_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "locations.boro = locations.boro.fillna(locations.zipcode.map(boro_dict))\n",
    "locations.loc[locations.boro.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review value counts\n",
    "locations.boro.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine queens and queens county\n",
    "locations.loc[locations.boro == \"Queens County\", \"boro\"] = \"Queens\"\n",
    "locations.boro = locations.boro.astype(\"string\").astype(\"category\")\n",
    "locations.boro.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update export path as needed\n",
    "\n",
    "exportpath = datapath[:-4] + \"_locations.csv\"\n",
    "locations.to_csv(exportpath, index=False)\n",
    "\n",
    "exportpath = datapath[:-4] + \"_locations.parquet\"\n",
    "locations.to_parquet(exportpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where did the Bronx Go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data of interest\n",
    "datapath = \"data/NY_2019.csv\"\n",
    "\n",
    "col_select = [\n",
    "    \"startstationid\",\n",
    "    \"startstationname\",\n",
    "    \"startstationlatitude\",\n",
    "    \"startstationlongitude\",\n",
    "]\n",
    "col_types = {\"startstationid\": \"category\", \"startstationname\": \"category\"}\n",
    "\n",
    "stations = pd.read_csv(datapath, index_col=False, usecols=col_select, dtype=col_types)\n",
    "\n",
    "# format, drop duplicates, drop na\n",
    "stations.rename(\n",
    "    columns={\n",
    "        \"startstationid\": \"stationid\",\n",
    "        \"startstationname\": \"stationname\",\n",
    "        \"startstationlatitude\": \"latitude\",\n",
    "        \"startstationlongitude\": \"longitude\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wherebronx = stations.loc[stations.stationid.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wherebronx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize geocode\n",
    "geolocator = Nominatim(user_agent=\"bikegeocode\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1, max_retries=0)\n",
    "\n",
    "# pull geolocation data for each station\n",
    "locations_lst = []\n",
    "for index, row in wherebronx.iterrows():\n",
    "    locations_lst.append(\n",
    "        reverse(\"{}, {}\".format(row[\"latitude\"], row[\"longitude\"])).raw[\"address\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_stationid = pd.DataFrame(locations_lst)\n",
    "miss_stationid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_stationid.suburb.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docking Station - Geo EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data if not generated above\n",
    "locations = pd.read_parquet(\"data/NY_2019_locations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.histplot(\n",
    "    locations.neighborhood.value_counts(),\n",
    "    bins=locations.neighborhood.value_counts().nunique(),\n",
    ")\n",
    "ax.set(xlabel=\"Count of Neighborhoods\", ylabel=\"Number of Docking Stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "x = sns.countplot(\n",
    "    x=locations.neighborhood, order=locations.neighborhood.value_counts().index[:20]\n",
    ")\n",
    "x.set_xticklabels(x.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "x.set(title=\"Count of Stations per neighborhood [top 20]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "x = sns.countplot(x=locations.boro, order=locations.boro.value_counts().index)\n",
    "# x.set_xticklabels(x.get_xticklabels(),rotation=45,horizontalalignment='right')\n",
    "x.set(title=\"Count of Stations per boro\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df166cf616f39a8b0c2f66e83ba2afdd6bfc8b57008690bcf278f179dbfb1b31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
