{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Profile memory usage\n",
    "We notice that our data files are large and pandas dataframes approach the limit of what can be handled on a 16GiB RAM computer when reading in a whole year's worth of trip data.\n",
    "This notebook simply profiles memory usage and improvements possible by\n",
    "* Using smaller numeric types\n",
    "* Using `categorical` type instead of `object` (strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial Memory Usage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/NY_2019.csv\")\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20551697 entries, 0 to 20551696\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   tripduration           int64  \n",
      " 1   starttime              object \n",
      " 2   stoptime               object \n",
      " 3   startstationid         float64\n",
      " 4   startstationname       object \n",
      " 5   startstationlatitude   float64\n",
      " 6   startstationlongitude  float64\n",
      " 7   endstationid           float64\n",
      " 8   endstationname         object \n",
      " 9   endstationlatitude     float64\n",
      " 10  endstationlongitude    float64\n",
      " 11  bikeid                 int64  \n",
      " 12  usertype               object \n",
      " 13  birthyear              int64  \n",
      " 14  gender                 int64  \n",
      "dtypes: float64(6), int64(4), object(5)\n",
      "memory usage: 8.8 GB\n"
     ]
    }
   ],
   "source": [
    "# initial usage, no optimization. see column dtypes\n",
    "df.info(memory_usage='deep')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.841 GiB\n"
     ]
    }
   ],
   "source": [
    "# Total GiB (same as above)\n",
    "start_memory = df.memory_usage(index=False, deep=True).sum()/(2**30)\n",
    "print(f'{round(start_memory, 3)} GiB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use smaller numeric types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223372036854775807\n",
      "2147483647\n",
      "32767\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "# Max int values (we have no negative numbers in our data)\n",
    "print(np.iinfo(np.int64).max)\n",
    "print(np.iinfo(np.int32).max)\n",
    "print(np.iinfo(np.int16).max)\n",
    "print(np.iinfo(np.int8).max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max values:\n",
      "3812666\n",
      "3911.0\n",
      "3911.0\n",
      "42088\n",
      "2003\n",
      "\n",
      "Min values:\n",
      "61\n",
      "72.0\n",
      "72.0\n",
      "14529\n",
      "1857\n"
     ]
    }
   ],
   "source": [
    "# What is the max for each numeric column?\n",
    "\n",
    "print(\"Max values:\")\n",
    "# okay who took a 1000+ hour (44 days) trip...should we drop outliers? perhaps not because then we can't determine bike rebalancing\n",
    "print(df.tripduration.max())\n",
    "print(df['startstationid'].max())\n",
    "print(df['endstationid'].max())\n",
    "print(df.bikeid.max())\n",
    "print(df.birthyear.max())\n",
    "\n",
    "# NOTE: we have no negative values (as expected) so can use unsigned ints when downcasting\n",
    "print(\"\\nMin values:\")\n",
    "print(df.tripduration.min())\n",
    "print(df['startstationid'].min())\n",
    "print(df['endstationid'].min())\n",
    "print(df.bikeid.min())\n",
    "print(df.birthyear.min())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Drop NAs before downcasting\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# # Use smaller numeric types\n",
    "# df['tripduration'] = df['tripduration'].astype('int32')\n",
    "# df['startstationid'] = df['startstationid'].astype('int16')\n",
    "# df['endstationid'] = df['endstationid'].astype('int16')\n",
    "# df['bikeid'] = df['bikeid'].astype('int32')\n",
    "# df['birthyear'] = df['birthyear'].astype('int16')\n",
    "# df['gender'] = df['gender'].astype('int8')\n",
    "\n",
    "# actually, let's downcast automatically instead of manually...\n",
    "# NOTE: we might lose precision, but not sure if that matters based on the operations we perform on these columns\n",
    "# E.g., float32 gives 6 digits of precision as opposed to 15 for float64. Need to check lat, long if this is okay\n",
    "for column in df:\n",
    "    if df[column].dtype == 'float64':\n",
    "        df[column] = pd.to_numeric(df[column], downcast='float')\n",
    "    if df[column].dtype == 'int64':\n",
    "        df[column] = pd.to_numeric(df[column], downcast='unsigned')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.941 GiB\n"
     ]
    }
   ],
   "source": [
    "# profile memory again\n",
    "downcasted_memory = df.memory_usage(index=False, deep=True).sum()/(2**30)\n",
    "print(f'{round(downcasted_memory, 3)} GiB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use categorical type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df['usertype'] = df['usertype'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.683 GiB\n"
     ]
    }
   ],
   "source": [
    "# profile memory again\n",
    "categorical_memory = df.memory_usage(index=False, deep=True).sum()/(2**30)\n",
    "print(f'{round(categorical_memory, 3)} GiB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DateTime\n",
    "Not sure if this will reduce or increase size. But it's necessary to do for our time series analysis anyways, so let's see"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "df['starttime'] = pd.to_datetime(df['starttime'])\n",
    "df['stoptime'] = pd.to_datetime(df['stoptime'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.889 GiB\n"
     ]
    }
   ],
   "source": [
    "# profile memory again\n",
    "datetime_memory = df.memory_usage(index=False, deep=True).sum()/(2**30)\n",
    "print(f'{round(datetime_memory, 3)} GiB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outcome\n",
    "Wow! Using DateTime helps a lot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataframe size by 56.01%\n"
     ]
    }
   ],
   "source": [
    "print(f'Reduced dataframe size by {round(100*(start_memory - datetime_memory)/start_memory, 2)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}